{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdcc5329"
   },
   "source": [
    "# LoRA Distillation Pipeline\n",
    "\n",
    "This notebook demonstrates the full pipeline for knowledge‑distillation fine‑tuning of `roberta-base` on AG News using LoRA adapters.\n",
    "\n",
    "**Contents:**\n",
    "1. Imports & Configuration  \n",
    "2. Helper Functions  \n",
    "3. Data Loading & Preview  \n",
    "4. Teacher Logit Generation  \n",
    "5. Logit Distribution Visualization  \n",
    "6. Student Model & LoRA Setup  \n",
    "7. Distillation Training & Evaluation  \n",
    "8. Training Curves Visualization  \n",
    "9. Parameter Count   \n",
    "10. Inference on Unlabelled Test Set  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T16:59:57.706342Z",
     "iopub.status.busy": "2025-04-10T16:59:57.706076Z",
     "iopub.status.idle": "2025-04-10T17:00:10.820735Z",
     "shell.execute_reply": "2025-04-10T17:00:10.819608Z",
     "shell.execute_reply.started": "2025-04-10T16:59:57.706321Z"
    },
    "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7"
   },
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np, pandas as pd, torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    RobertaForSequenceClassification, RobertaTokenizer,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Global config\n",
    "BASE_MODEL        = \"roberta-base\"\n",
    "NUM_EPOCHS        = 3\n",
    "BATCH_SIZE_TRAIN  = 16\n",
    "BATCH_SIZE_EVAL   = 64\n",
    "LEARNING_RATE     = 2e-4\n",
    "TEMPERATURE       = 2.0\n",
    "ALPHA             = 0.7\n",
    "LORA_RANK         = 8\n",
    "LORA_ALPHA        = 16\n",
    "LORA_DROPOUT      = 0.1\n",
    "LORA_START        = 6\n",
    "LORA_END          = 11\n",
    "DEVICE            = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T17:00:18.024000Z",
     "iopub.status.busy": "2025-04-10T17:00:18.023716Z",
     "iopub.status.idle": "2025-04-10T17:00:43.072941Z",
     "shell.execute_reply": "2025-04-10T17:00:43.072308Z",
     "shell.execute_reply.started": "2025-04-10T17:00:18.023975Z"
    },
    "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263"
   },
   "outputs": [],
   "source": [
    "def make_lora_target_modules(start, end):\n",
    "    modules = [\"attention.self.query\",\"attention.self.value\",\"output.dense\"]\n",
    "    return [f\"encoder.layer.{i}.{m}\" for i in range(start, end+1) for m in modules]\n",
    "\n",
    "def distillation_loss(student_logits, teacher_logits, labels, T, alpha):\n",
    "    kl = F.kl_div(\n",
    "        input=F.log_softmax(student_logits / T, dim=-1),\n",
    "        target=F.softmax(teacher_logits / T, dim=-1),\n",
    "        reduction=\"batchmean\"\n",
    "    ) * (T*T)\n",
    "    ce = F.cross_entropy(student_logits, labels)\n",
    "    return alpha*kl + (1-alpha)*ce\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = evaluate.load(\"accuracy\").compute(predictions=preds, references=pred.label_ids)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "def evaluate_model(model, dataset, collator, batch_size=8):\n",
    "    \"\"\"\n",
    "    Run evaluation manually: returns (metrics_dict, predictions_array).\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collator)\n",
    "    model.to(DEVICE).eval()\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            labels = batch.pop(\"labels\", None)\n",
    "            idxs   = batch.pop(\"idx\", None)\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            logits = model(**batch).logits\n",
    "            preds  = logits.argmax(dim=-1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            if labels is not None:\n",
    "                metric.add_batch(predictions=preds, references=labels.numpy())\n",
    "    return metric.compute(), np.array(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Preview\n",
    "\n",
    "- Load AG News training split.\n",
    "- Tokenize texts.\n",
    "- Preview first 5 samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T17:00:46.777431Z",
     "iopub.status.busy": "2025-04-10T17:00:46.776751Z",
     "iopub.status.idle": "2025-04-10T17:02:00.673160Z",
     "shell.execute_reply": "2025-04-10T17:02:00.672331Z",
     "shell.execute_reply.started": "2025-04-10T17:00:46.777399Z"
    },
    "id": "21f42747-f551-40a5-a95f-7affb1eba4a3"
   },
   "outputs": [],
   "source": [
    "raw = load_dataset(\"ag_news\", split=\"train\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "def preprocess_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=False)\n",
    "\n",
    "tokenized = raw.map(preprocess_fn, batched=True).rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Preview\n",
    "pd.DataFrame({\"text\": raw[\"text\"][:5], \"label\": raw[\"label\"][:5]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Teacher Logit Generation\n",
    "\n",
    "- Wrap dataset with CustomDataset + DataCollatorWithIdx.\n",
    "- Load teacher model and generate logits for each training example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, hf_ds): ...\n",
    "    def __len__(self): ...\n",
    "    def __getitem__(self, idx): ...\n",
    "\n",
    "class DataCollatorWithIdx(DataCollatorWithPadding):\n",
    "    def __call__(self, features): ...\n",
    "\n",
    "split = tokenized.train_test_split(test_size=640, seed=42)\n",
    "train_ds = CustomDataset(split[\"train\"])\n",
    "collator = DataCollatorWithIdx(tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "teacher = RobertaForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL, id2label=id2label, label2id={v:k for k,v in id2label.items()}\n",
    ").to(DEVICE).eval()\n",
    "\n",
    "teacher_logits = torch.zeros(len(train_ds), num_labels)\n",
    "for batch in tqdm(DataLoader(train_ds, batch_size=64, collate_fn=collator), desc=\"Teacher\"):\n",
    "    idxs = batch.pop(\"idx\")\n",
    "    inputs = {k:v.to(DEVICE) for k,v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = teacher(**inputs).logits.cpu()\n",
    "    teacher_logits[idxs] = logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logit Distribution Visualization\n",
    "\n",
    "Plot a histogram of all teacher logits to inspect their distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = teacher_logits.flatten().numpy()\n",
    "plt.hist(vals, bins=50)\n",
    "plt.title(\"Teacher Logit Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Student Model & LoRA Setup\n",
    "\n",
    "- Load base RoBERTa.\n",
    "- Inject LoRA adapters.\n",
    "- Print number of trainable parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = RobertaForSequenceClassification.from_pretrained(BASE_MODEL)\n",
    "lora_cfg = LoraConfig(\n",
    "    r=LORA_RANK, lora_alpha=LORA_ALPHA, lora_dropout=LORA_DROPOUT,\n",
    "    target_modules=make_lora_target_modules(LORA_START, LORA_END),\n",
    "    bias=\"none\", task_type=\"SEQ_CLS\"\n",
    ")\n",
    "peft_model = get_peft_model(student, lora_cfg)\n",
    "peft_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Distillation Training & Evaluation\n",
    "\n",
    "- Set up `TrainingArguments`.\n",
    "- Override `compute_loss` to use our `distillation_loss`.\n",
    "- Train with `Trainer` and evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results/model_checkpoint\",\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_SIZE_EVAL,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "def compute_loss(model, inputs, return_outputs=False):\n",
    "    # copy-paste 上面第7 步的实现\n",
    "    ...\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=CustomDataset(split[\"test\"]),\n",
    "    data_collator=collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    compute_loss=compute_loss\n",
    ")\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"Validation Accuracy: {metrics['eval_accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Curves Visualization\n",
    "\n",
    "Use the trainer’s log history to plot training loss and validation accuracy over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hist = pd.DataFrame(trainer.state.log_history)\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,4))\n",
    "hist['loss'].plot(ax=axes[0], title='Train Loss')\n",
    "hist['eval_accuracy'].plot(ax=axes[1], title='Eval Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Parameter Count\n",
    "\n",
    "Compute and display total vs. trainable parameter counts (in millions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(p.numel() for p in peft_model.parameters())\n",
    "trainable = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "print(f\"Total Params: {total/1e6:.2f}M\")\n",
    "print(f\"Trainable Params: {trainable/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inference on Unlabelled Test Set\n",
    "\n",
    "Run the `inference.py` script to generate `submission.csv`, then preview the first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../scripts/inference.py \\\n",
    "  --checkpoint results/model_checkpoint \\\n",
    "  --test_file ../data/test_unlabelled.pkl \\\n",
    "  --output_csv submission.csv\n",
    "\n",
    "import pandas as pd\n",
    "pd.read_csv(\"submission.csv\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
